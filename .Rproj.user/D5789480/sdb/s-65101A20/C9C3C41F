{
    "collab_server" : "",
    "contents" : "############################################################\n#     Foundation to Strategic Business Analytics           #\n#       Module 2 - Finding groups within data        \t\t\t #\n#                                                  \t\t\t\t #\n#                                                          #\n# \tAuthor: Nicolas Glady & Pauline Glikman                #\n#                   ESSEC BUSINESS SCHOOL                  #\n############################################################\n\n############################################################\n# Disclaimer: this script is used to produce the examples  #\n#  presented during the course Strategic Business          #\n#  Analytics. The author is not responsible in any way     #\n#  for any problem encountered during this code execution. #\n############################################################\n\n############################################################\n####        EXAMPLE N°1 - STOCK KEEPING UNIT            ####\n############################################################\n# Set your directory to the folder where you have downloaded the SKU dataset\n\n# To clean up the memory of your current R session run the following line\nrm(list=ls(all=TRUE))\n\n# Let's load our dataset\ndata=read.table('DATA_2.01_SKU.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files\n\n# Now let's have a look at our variables and see some summary statistics\nstr(data) # The str() function shows the structure of your dataset and details the type of variables that it contains\nsummary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles\n\n# Let's plot our data to see if we can identify groups visually \nplot(data$CV, data$ADS, main = \"SKU Example\", ylab=\"Average Daily Sales\", xlab= \"Coefficient of Variation\")\nabline(v=0.2, col = \"red\") # we can draw a vertical line by using the abline function and passing it the v argument\nabline(h=4, col=\"red\") # we can draw a horizontal line by using the abline function and passing it the h argument\ntext(0.15,9.7, \"Horses\", col = \"red\") # we can add some text to our plot by using the text() function, here to label the group \"Horses\"\ntext(0.65,9, \"Wild Bulls\", col = \"red\") # and group \"Wild Bulls\"\ntext(0.8,2, \"Crickets\", col = \"red\") # and group \"Crickets\"\n\n\n# Let's find groups using hierarchical clustering and check if we obtain similar results\ntestdata=data  # To keep our dataset safe, let's create a copy of it called \"testdata\"\ntestdata = scale(testdata) # To keep our dataset safe, let's create a copy of it called \"testdata\"\n\nd = dist(testdata, method = \"euclidean\") # the dist() function computes the distances of all the observations in our dataset\nhcward = hclust(d, method=\"ward.D\") # hclust() function performs hiearchical clustering, we pass it the distances, and we set the method argument to \"ward.D\"\n\ndata$groups<-cutree(hcward,k=3) # assign our points to our k=3 clusters \n\n# The lattice library provides a complete set of functions for producing advanced plots.\ninstall.packages(\"lattice\") #install the lattice package by using the install.packages() function\nlibrary(lattice) # load the lattice package by using the library() function and passing it the name of the package you wish to load\nxyplot(ADS~ CV,main = \"After Clustering\", type=\"p\",group=groups,data=data, # define the groups to be differentiated \n       auto.key=list(title=\"Group\", space = \"left\", cex=1.0, just = 0.95), # to produce the legend we use the auto.key= list() \n       par.settings = list(superpose.line=list(pch = 0:18, cex=1)), # the par.settings argument allows us to pass a list of display settings\n       col=c('blue','green','red')) # finally we choose the colour of our plotted points per group\n\n\n###########################################################\n####     EXAMPLE N°2 - HUMAN RESSOURCES ANALYTICS      ####\n###########################################################\n\n# Set your directory to the folder where you have downloaded the HR dataset \n\n# To clean up the memory of your current R session run the following line\nrm(list=ls(all=TRUE))\n\n# Let's load our dataset and call it data\ndata=read.table('DATA_2.02_HR.csv',header = T,sep=',') # The function read.table enables us to read flat files such as .csv files\n\n# Now let's have a look at our variables and see some summary statistics\nstr(data) # The str() function shows the structure of your dataset and details the type of variables that it contains\nsummary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles\n\n# Now let's normalize our variables\ntestdata=data # To keep our dataset safe, let's create a copy of it called \"testdata\"\ntestdata = scale(testdata) # the scale function automatically performs data normalization on all your variables\n\nd = dist(testdata, method = \"euclidean\") # the dist() function computes the distances of all the observations in our dataset\nhcward = hclust(d, method=\"ward.D\") # hclust() function performs hiearchical clustering, we pass it the distances, and we set the method argument to \"ward.D\"\n\ndata$groups = cutree(hcward,k=4) # assign our points to our k=4 clusters \n\naggdata = aggregate(.~ groups, data=data, FUN=mean) # The aggregate() function presents a summary of a statistic, broken down by one or more groups. Here we compute the mean of each variable for each group. \n\n# One thing we would like to have is the proportion of our data that is in each cluster\nproptemp=aggregate(S~ groups, data=data, FUN=length) # we create a variable called proptemp which computes the number of observations in each group (using the S variable, but you can take any.)\naggdata$proportion=(proptemp$S)/sum(proptemp$S) # proportion of observations in each group we compute the ratio between proptemp and the total number of observations\naggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Let's order the groups from the larger to the smaller\n\n# Let's see the output by calling our aggdata variable\naggdata\n\n# As discussed in the videos, let's remove the Newborn variable, which is not really relevant and by being a dummy drives the clustering too much...\ntestdata=data[,1:5] # we create a new dataset, called \"testdata\" includes all the rows and the 5 first columns of our original dataset \n\n# We then rerun the code used above\ntestdata = scale(testdata) # We normalize again our original variables\nd = dist(testdata, method = \"euclidean\") # We compute the distances between observations\nhcward = hclust(d, method=\"ward.D\") # Hiearchical Clustering using Ward criterion\n\ndata$groups = cutree(hcward,k=4) # Create segments for k=4\n# Note that we re-use the original dataset \"data\" (where the variable Newborn is still present) and not \"testdata\" (where the variable Newborn has been removed)\n# Hence we'll be able to produce summary statistics also for the Newborn variable regardless it wasn't included when doing the second version of the clustering\n\naggdata = aggregate(.~ groups, data=data, FUN=mean) # Aggregate the values again\n\nproptemp=aggregate(S~ groups, data=data, FUN=length)  # Compute the number of observations per group\naggdata$proportion=(proptemp$S)/sum(proptemp$S) # Compute the proportion\naggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Let's order the groups from the larger to the smaller\n\n# Let's see the output by calling our aggdata variable\naggdata \n\n# To export the output of our result, we execute the following line using the write.table() function\n# write.csv(aggdata, \"HR_example_Numerical_Output.csv\", row.names=FALSE)\n# This allows to import the data in Excel for instance where we can prepare it for the presentation. E.g. change the name of the columns, use colours, etc.\n# Instead of write.csv, you can also use write.csv2() if you encounter an error due to regional settings for separators\n\n\n###########################################################\n####        EXAMPLE N°3 - TELECOMMUNICATIONS           ####\n###########################################################\n\n# Set your directory to the folder where you have downloaded the Telco dataset \n\n# to clean up the memory of your current R session run the following line\nrm(list=ls(all=TRUE))\n\n# Let's load the data\ndata=read.table('DATA_2.03_Telco.csv', header = T,sep=',')# The function read.table enables us to read flat files such as .csv files\n\n# Now let's have a look at our variables and see some summary statistics\nstr(data) # The str() function shows the structure of your dataset and details the type of variables that it contains\nsummary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles\n\n# Now let's normalize our variables\ntestdata=data # To keep our dataset safe, let's create a copy of it called \"testdata\"\ntestdata = scale(testdata) # the scale function automatically performs data normalization on all your variables\n\nd = dist(testdata, method = \"euclidean\") # the dist() function computes the distances of all the observations in our dataset\nhcward = hclust(d, method=\"ward.D\") # hclust() function performs hiearchical clustering, we pass it the distances, and we set the method argument to \"ward.D\"\n\ndata$groups=cutree(hcward,k=8) # assign our points to our k=8 clusters \naggdata= aggregate(.~ groups, data=data, FUN=mean) # Aggregation by group and computation of the mean values\nproptemp=aggregate(Calls~ groups, data=data, FUN=length) # Computation of the number of observations by group\naggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls) # Computation of the proportion by group\naggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Ordering from the largest group to the smallest\n\n\n# Let's try again with 5 segments\ndata$groups= cutree(hcward,k=5) #Create segments for k=5\naggdata= aggregate(.~ groups, data=data, FUN=mean) # Aggregation by group and computation of the mean values\nproptemp=aggregate(Calls~ groups, data=data, FUN=length) # Computation of the number of observations by group\naggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls) # Computation of the proportion by group\naggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Ordering from the largest group to the smallest\n\n#write.csv(aggdata, file = \"aggdataTelco5seg.csv\", row.names=FALSE) # Let's save the output in a csv to work on it in Excel later\n\n# Let's draw the radar chart with the function stars()\npalette(rainbow(12, s = 0.6, v = 0.75)) # Select the colors to use\nstars(aggdata[,2:(ncol(data))], len = 0.6, key.loc = c(11, 6),xlim=c(2,12),main = \"Segments\", draw.segments = TRUE,nrow = 2, cex = .75,labels=aggdata$groups)\n\n\n",
    "created" : 1497793179759.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "604982667",
    "id" : "C9C3C41F",
    "lastKnownWriteTime" : 1442356338,
    "last_content_update" : 1442356338,
    "path" : "~/Documents/DataScience/courses/ESSEC_SBA/Intro_SBA/FSBA_SCRIPT_MODULE2.R",
    "project_path" : "FSBA_SCRIPT_MODULE2.R",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}